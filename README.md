# ðŸ“š PDF Q&A System with RAG Architecture

**This is basic first version, feel free to suggest or add updates to the project**

A modern, intelligent document analysis system that enables users to upload PDF documents and ask questions about their content using advanced AI techniques.

## ðŸŽ¯ Overview

This project implements a **Retrieval-Augmented Generation (RAG)** system that combines document processing, vector similarity search, and large language models to provide accurate, source-attributed answers to questions about PDF documents.

## Screenshot

![Screenshot](assets/screenshot.jpg)

## âœ¨ Features

- ðŸ“„ **PDF Document Processing** - Upload and process multiple PDF files
- ðŸ” **Intelligent Search** - Vector-based semantic similarity search using FAISS
- ðŸ¤– **AI-Powered Q&A** - Integration with Groq's Llama 3.3 70B model
- ðŸ“š **Source Attribution** - Every answer includes references to source documents
- ðŸŒ **Web Interface** - Clean, interactive Streamlit web application
- âš™ï¸ **Configurable Parameters** - Adjustable chunk sizes, retrieval settings, and model selection
- ðŸ’¬ **Real-time Chat** - Interactive conversation interface with history

## ðŸ—ï¸ Architecture

**RAG System Pipeline:**

1. **ðŸ“ Documents** â†’ Upload PDF files
2. **ðŸ“ Text Extraction** â†’ Extract readable content
3. **âœ‚ï¸ Chunking** â†’ Split into overlapping segments
4. **ðŸ”¢ Vector Embeddings** â†’ Convert text to numerical vectors
5. **ðŸ—„ï¸ FAISS Database** â†’ Store vectors for fast retrieval
6. **ðŸ” Similarity Search** â†’ Find most relevant chunks
7. **ðŸ“‹ Context Assembly** â†’ Combine relevant information
8. **ðŸ¤– LLM Response** â†’ Generate intelligent answer

â“ User Question â†’ ðŸ” Similarity Search

## ðŸ› ï¸ Technology Stack

- **Backend**: Python, LangChain, FAISS, Sentence Transformers
- **LLM**: Groq API (Llama 3.3 70B)
- **Frontend**: Streamlit
- **Document Processing**: PyMuPDF, PyPDF2
- **Vector Store**: FAISS with CPU optimization

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Groq API key ([Get one here](https://console.groq.com/))

### Installation

1. **Clone the repository**
   git clone https://github.com/yourusername/PDF-QA-LangChain-RAG.git
   cd PDF-QA-LangChain-RAG

2. **Install dependencies**
   pip install -r requirements.txt

3. **Set up API key**
    echo "GROQ_API_KEY = 'your-api-key-here'" > config.py

4. **Run the application**
    streamlit run src/app.py

5. Open your browser to `http://localhost:8501`

## ðŸ“– Usage

1. **Upload Documents**  
    Use the sidebar to upload your own PDF files or load sample documents.

2. **Process Documents**  
    Click **Process Documents** to generate vector embeddings from your PDFs.

3. **Ask Questions**  
    Enter your questions in the chat interface to query the document content.

4. **View Sources**  
    Expand the source details to see which documents and sections the answers are based on.

5. **Configure Settings**  
    Adjust model selection, chunk sizes, and retrieval parameters in the sidebar as needed.

## ðŸ“‚ Project Structure

```
PDF-QA-LangChain-RAG/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                 # Streamlit web application
â”‚   â”œâ”€â”€ document_loader.py     # PDF loading and text extraction
â”‚   â”œâ”€â”€ document_processor.py  # Text chunking and preprocessing
â”‚   â”œâ”€â”€ vector_store.py        # FAISS vector database management
â”‚   â””â”€â”€ rag_chain.py           # RAG pipeline and LLM integration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_pdfs/          # Sample documents for testing
â”‚   â””â”€â”€ vector_store/         # Saved vector databases
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```        

## ðŸ”§ Configuration

**Model Options**
- `llama-3.3-70b-versatile` (Recommended) â€“ High quality responses
- `mixtral-saba-24b` â€“ Alternative option

**Processing Parameters**
- **Chunk Size:** 500â€“2000 characters (default: 1000)
- **Chunk Overlap:** 50â€“500 characters (default: 200)
- **Retrieval Count:** 1â€“10 chunks (default: 3)

## ðŸ§ª Testing

**Test document loading**
python src/document_loader.py

**Test document processing**
python src/document_processor.py

**Test vector store**
python src/vector_store.py

**Test RAG chain**
python src/rag_chain.py
